# Claude Code Instructions - Auto-Loaded Context (Backend API)

**Purpose**: Automatically loaded instructions for every Claude Code session
**Repository**: breederhq-api (Backend API)

---

## Session Start Acknowledgment

**At the start of every new session**, before responding to any user request, acknowledge that you have loaded these instructions by saying:

> "CLAUDE.md loaded for breederhq-api. Context docs imported. Key rules I will follow:
> - ALL queries MUST filter by tenantId (data leak risk otherwise)
> - ALL protected routes MUST use requireAuth middleware
> - ALL input MUST be validated with Zod schemas
> - ALL list endpoints MUST be paginated
> - No N+1 queries, no unbounded results
> - Media: Public images via `getPublicCdnUrl()`, private files via `generatePresignedDownloadUrl()`
> - Media: All S3 uploads MUST set `CacheControl: public, max-age=31536000, immutable`
> - **Schema changes: Write SQL migrations with dbmate, NEVER edit schema.prisma models directly**
> - **Migrations: `npm run db:new <name>` → write SQL → `npm run db:dev:sync`**
> - TypeScript: Zero errors policy - I will run tsc and fix all errors before finishing"

This confirms the instructions are active and that Claude has read the imported documentation.

---

## Imported Documentation (auto-loaded into context)

@docs/CLAUDE-CODE-CONTEXT.md

---

## Database Migrations (dbmate - MANDATORY)

**This project uses dbmate for SQL migrations and Prisma as ORM only.**

### CRITICAL RULES

1. **NEVER edit `prisma/schema.prisma` models directly** — the schema is generated by `prisma db pull`
2. **NEVER run `prisma migrate dev`**, `prisma migrate deploy`, or any `prisma migrate` command
3. **ALL schema changes MUST be written as raw SQL** in dbmate migration files
4. **`schema.prisma` is read-only** for models/enums — only edit the `datasource` and `generator` blocks

### How to Make Schema Changes

```bash
# 1. Create a new migration file
npm run db:new add_something

# 2. Edit the generated file: db/migrations/YYYYMMDDHHMMSS_add_something.sql
#    Write your SQL in the -- migrate:up section
#    Write the rollback in the -- migrate:down section

# 3. Apply migration + sync Prisma schema + regenerate client
npm run db:dev:sync
```

### Migration File Format

```sql
-- migrate:up
CREATE TABLE "public"."orders" (
  "id" SERIAL PRIMARY KEY,
  "tenantId" INTEGER NOT NULL REFERENCES "public"."tenants"("id"),
  "total" INTEGER NOT NULL DEFAULT 0,
  "createdAt" TIMESTAMP NOT NULL DEFAULT NOW()
);

CREATE INDEX "idx_orders_tenantId" ON "public"."orders"("tenantId");

-- migrate:down
DROP TABLE IF EXISTS "public"."orders";
```

### Available Commands

| Command | Description |
|---------|-------------|
| `npm run db:new <name>` | Create a new migration file |
| `npm run db:dev:up` | Apply pending migrations to dev |
| `npm run db:dev:down` | Rollback last migration on dev |
| `npm run db:dev:sync` | Apply + pull schema + regenerate client |
| `npm run db:dev:status` | Show migration status (dev) |
| `npm run db:prod:deploy` | Apply pending migrations to prod |
| `npm run db:prod:status` | Show migration status (prod) |
| `npm run db:pull` | Introspect DB and update schema.prisma |
| `npm run db:gen` | Regenerate Prisma Client |

### Multi-Schema Support

This project uses two PostgreSQL schemas: `public` and `marketplace`.
Always use schema-qualified table names in migrations:

```sql
-- Public schema (default)
CREATE TABLE "public"."my_table" (...);

-- Marketplace schema
CREATE TABLE "marketplace"."my_table" (...);
```

### Known Gotchas

**1. `prisma:validate` requires `run-with-env.js`, not `npx dotenv`**

`.env.dev.migrate` only contains `AWS_SECRET_NAME` — no actual `DATABASE_URL`. If you ever
see the `prisma:validate` script using `npx dotenv -e .env.dev.migrate`, that's wrong.
It must go through `run-with-env.js` so secrets are fetched from SM first:

```
"prisma:validate": "node scripts/development/run-with-env.js --quiet .env.dev.migrate prisma validate --schema=prisma/schema.prisma"
```

**2. Baseline SQL from `pg_dump` — always strip `schema_migrations`**

`pg_dump` includes the `schema_migrations` table and its primary key. dbmate creates and
owns that table itself. If you regenerate the baseline from a dump, remove these two blocks
before committing, otherwise `db:prod:deploy` fails with relation/primary-key-already-exists
errors on any database where dbmate has already initialized:

- `CREATE TABLE [IF NOT EXISTS] public.schema_migrations (...)`
- `ALTER TABLE ONLY public.schema_migrations ADD CONSTRAINT schema_migrations_pkey ...`

---

### Self-Check for Schema Changes

- [ ] Did I create a dbmate migration file (NOT edit schema.prisma)?
- [ ] Does the migration have both `-- migrate:up` and `-- migrate:down`?
- [ ] Did I use schema-qualified table names?
- [ ] Did I run `npm run db:dev:sync` to apply and sync?
- [ ] After sync, does `prisma validate` still pass?
- [ ] Did I run `tsc --noEmit` to verify types?

---

## Key Reminders (Backend)

### ✅ Always:
- Filter by `tenantId` in ALL queries
- Use `requireAuth` middleware on protected routes
- Paginate list endpoints (`take` and `skip`)
- Validate input with Zod schemas
- Handle errors with try/catch
- Return pagination metadata (`page`, `limit`, `total`, `totalPages`)

### ❌ Never:
- Query without tenant filter (data leak risk!)
- Return all records (performance issue)
- Skip authentication checks (security issue)
- Trust user input directly (injection risk)
- Query in loops (N+1 performance issue)
- Send raw Prisma objects with BigInt fields via `reply.send()` without conversion (see BigInt section below)

---

## BigInt Serialization (ENFORCED)

**`JSON.stringify` cannot serialize BigInt values.** Prisma returns `BigInt` for PostgreSQL `bigint`/`int8` columns.

### Global Safety Net

A `BigInt.prototype.toJSON` shim exists in `server.ts` that auto-converts BigInt → Number during serialization. This prevents 500 errors but is a **last resort**, not a design pattern.

### BigInt Fields in This Codebase

| Model | Fields | Type |
|-------|--------|------|
| Invoice | `amountCents`, `balanceCents`, `depositCents`, `refundedCents` | BigInt |
| Contact | `marketplaceTotalSpentCents` | BigInt |
| MarketplaceProvider | `totalRevenueCents`, `lifetimePayoutCents` | BigInt |
| MarketplaceTransaction | `totalCents`, `platformFeeCents`, `providerPayoutCents`, `taxCents`, etc. | BigInt |
| MktListingServiceListing | `priceCents` | BigInt |

### Best Practice: Explicit Conversion in Serializer Functions

When writing serializer/DTO functions, always convert BigInt fields explicitly:

```typescript
// ✅ CORRECT - Explicit conversion
const dto = {
  totalCents: Number(invoice.amountCents),
  balanceCents: Number(invoice.balanceCents),
};

// ✅ ALSO CORRECT - Use Prisma `select` to avoid including BigInt fields you don't need
const contact = await prisma.contact.findFirst({
  where: { id },
  select: { id: true, display_name: true, email: true }, // No BigInt fields
});

// ❌ RISKY - Spreading raw Prisma objects that may contain BigInt
reply.send({ ...rawPrismaResult }); // May contain BigInt fields!
```

### Self-Check Before Sending Responses

- [ ] Does the Prisma result include any BigInt columns?
- [ ] Did I convert them with `Number()` in the serializer?
- [ ] Or did I use `select` to exclude unneeded BigInt fields?

---

## TypeScript Discipline (ENFORCED)

**Zero TypeScript errors policy. No exceptions.**

### After Every Code Change

After modifying or creating TypeScript files, **ALWAYS** verify compilation before considering the task complete:

```bash
npx tsc --noEmit
```

### Rules

1. **Fix errors immediately** - Do not defer, do not ask permission, just fix them
2. **Re-run until clean** - Keep fixing and re-checking until zero errors
3. **No implicit any** - All parameters and variables must be typed
4. **No @ts-ignore** - Find the real fix instead of suppressing errors
5. **No @ts-expect-error** - Unless absolutely necessary with a comment explaining why
6. **Handle nullability** - Use optional chaining (`?.`) and nullish coalescing (`??`)
7. **Type Prisma results** - Use generated Prisma types, don't cast to `any`

### Common Mistakes to Avoid

- Forgetting to import a type after using it
- Mismatched function signatures
- Missing properties on object literals
- Incorrect generic type parameters
- Using `any` instead of proper types
- Not handling `null | undefined` return types from Prisma
- Incorrect Express request/response typing

### Self-Review Before Finishing

Before marking any task complete, mentally verify:
- [ ] Did I run `tsc --noEmit`?
- [ ] Are there zero type errors?
- [ ] Did I import all necessary types?
- [ ] Are all function parameters typed?
- [ ] Did I handle null/undefined cases?

**Type errors are bugs, not warnings. A task is not complete until TypeScript compiles cleanly.**

---

## Before Starting Any Task

1. **Read the full context**: [docs/CLAUDE-CODE-CONTEXT.md](../docs/CLAUDE-CODE-CONTEXT.md)
2. **Search for patterns**: `grep -r "similar-endpoint" src/routes/`
3. **Check existing routes**: Look at similar endpoints in same module
4. **Verify auth**: All protected routes need `requireAuth` middleware

---

## Quick Reference

### List Endpoint Pattern
```typescript
app.get("/api/v1/resource", requireAuth, async (req, res) => {
  const tenantId = Number(req.headers["x-tenant-id"]);
  const page = Number(req.query.page) || 1;
  const limit = Math.min(Number(req.query.limit) || 50, 100);

  const where = { tenantId };

  const [data, total] = await Promise.all([
    prisma.resource.findMany({
      where,
      take: limit,
      skip: (page - 1) * limit,
    }),
    prisma.resource.count({ where }),
  ]);

  res.json({
    data,
    pagination: {
      page,
      limit,
      total,
      totalPages: Math.ceil(total / limit),
      hasNext: page * limit < total,
      hasPrevious: page > 1,
    },
  });
});
```

### Get By ID Pattern
```typescript
app.get("/api/v1/resource/:id", requireAuth, async (req, res) => {
  const tenantId = Number(req.headers["x-tenant-id"]);
  const id = Number(req.params.id);

  const resource = await prisma.resource.findFirst({
    where: { id, tenantId }, // ← Always check tenant
  });

  if (!resource) {
    return res.status(404).json({ error: "Not found" });
  }

  res.json(resource);
});
```

### Create Pattern
```typescript
const createSchema = z.object({
  name: z.string().min(1).max(100),
  // ... other fields
});

app.post("/api/v1/resource", requireAuth, async (req, res) => {
  const tenantId = Number(req.headers["x-tenant-id"]);

  try {
    const validated = createSchema.parse(req.body);

    const resource = await prisma.resource.create({
      data: {
        ...validated,
        tenantId, // ← Always include tenant
      },
    });

    res.status(201).json(resource);
  } catch (error) {
    if (error instanceof z.ZodError) {
      return res.status(400).json({ error: error.errors });
    }
    res.status(500).json({ error: "Internal server error" });
  }
});
```

---

## Security Checklist

Before submitting PR:
- [ ] All routes have `requireAuth` middleware
- [ ] All queries filter by `tenantId`
- [ ] All input is validated (Zod schemas)
- [ ] All errors are caught and handled
- [ ] No sensitive data in error messages

---

## Performance Checklist

Before submitting PR:
- [ ] List endpoints paginated
- [ ] No N+1 queries (use `include` or batch)
- [ ] Database indexes on filtered fields
- [ ] SELECT only needed fields

---

## PostgreSQL Enum Migrations (CRITICAL)

**PostgreSQL `ALTER TYPE ... ADD VALUE` cannot run inside a transaction.**

Dbmate wraps each migration in a transaction by default. You MUST disable this for enum additions.

### Adding a New Enum Value (Simple Case)

```sql
-- migrate:up transaction:false
ALTER TYPE "MyEnum" ADD VALUE IF NOT EXISTS 'NEW_VAL';

-- migrate:down
-- Note: PostgreSQL does not support removing enum values.
-- Use the text-conversion approach below if rollback is needed.
```

The `transaction:false` directive tells dbmate to run this migration outside a transaction.

### Adding Enum Value + Data Migration (Complex Case)

If you need to add a value AND update existing rows, use the text-conversion approach:

```sql
-- migrate:up
-- 1. Create new enum with desired values
CREATE TYPE "MyEnum_new" AS ENUM ('NEW_VAL', 'OTHER_VAL');

-- 2. Convert column to text
ALTER TABLE "MyTable" ALTER COLUMN "col" TYPE text USING ("col"::text);

-- 3. Remap old values to new values (safe - it's just text now)
UPDATE "MyTable" SET "col" = 'NEW_VAL' WHERE "col" = 'OLD_VAL';

-- 4. Cast to new enum
ALTER TABLE "MyTable" ALTER COLUMN "col" TYPE "MyEnum_new" USING ("col"::"MyEnum_new");

-- 5. Drop old, rename new
DROP TYPE "MyEnum";
ALTER TYPE "MyEnum_new" RENAME TO "MyEnum";

-- migrate:down
-- Reverse the process if needed
```

This approach works inside a transaction (no `transaction:false` needed).

---

**Auto-loaded by Claude Code at session start**
**Last Updated**: 2026-02-17 (Added BigInt serialization safety net and documentation)
